{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/circle0103/image_segmentation/blob/main/Copy_of_EML_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZdKXsfGhk-a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21pDb_GN2SDL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJmSwjJchyNN"
      },
      "outputs": [],
      "source": [
        "class retinaDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, length = 15):\n",
        "      'Initialization'\n",
        "      self.X = []\n",
        "      self.y = []\n",
        "      self.length = length\n",
        "  \n",
        "  def __len__(self):\n",
        "      'Denotes the total number of samples'\n",
        "      return self.length\n",
        "\n",
        "  def transform(self, image):\n",
        "      X = transforms.Compose([transforms.ToTensor()])(image)\n",
        "      return X\n",
        "\n",
        "  def transform_norm(self, image):\n",
        "    # data augmentation\n",
        "    X = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])(image)\n",
        "    # X1 = transforms.Compose(transforms.CenterCrop(10),transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), transforms.ToTensor())(image)\n",
        "    return X\n",
        "    \n",
        "\n",
        "  \n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "      'Generates one sample of data'\n",
        "      # Select sample\n",
        "      image = Image.open(f'{index + 1}_training.tif')\n",
        "      label = Image.open(f'{index + 1}_manual1.gif')\n",
        "      X = self.transform_norm(image)\n",
        "      y = self.transform(label)\n",
        "      return X, y\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6wLrwnSo9Lv",
        "outputId": "6c0c0569-8d86-4809-8194-e19f834c2260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "full_set = retinaDataset()\n",
        "fullloader = torch.utils.data.DataLoader(full_set, batch_size=1, shuffle=False, num_workers=0)\n",
        "trainset, valset = torch.utils.data.random_split(full_set, [10, 5])\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=3, shuffle=True, num_workers=0)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=1, shuffle=True, num_workers=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyCLIooByjSV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow_color(img,i):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    print(npimg.shape)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.title(f'image {i*5+1} to {i*5+5}')\n",
        "    plt.show()\n",
        "\n",
        "def imshow(img):\n",
        "    #img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def imshow_gpu(img):\n",
        "    #img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.cpu().numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pju2IxtmGS5y"
      },
      "outputs": [],
      "source": [
        "def imshow_rgb(i):\n",
        "  im = Image.open(f'{i}_training.tif').convert('RGB')\n",
        "  #display(im.getchannel('R'))\n",
        "  #display(im.getchannel('G'))\n",
        "  display(im.getchannel('B'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SPBA10GH2C14"
      },
      "outputs": [],
      "source": [
        "for i, (data, label) in enumerate(fullloader):\n",
        "  imshow_rgb(i+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVaX2ffeyrKn"
      },
      "outputs": [],
      "source": [
        "for i, (data, label) in enumerate(fullloader):\n",
        "  imshow_color(torchvision.utils.make_grid(data), i)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWw8tdetqgZV"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUnmIytm5TPj"
      },
      "source": [
        "We use U-Net architecture to train our model since Unet performed well emperically and has been an popular convolutional neural network architecture for semantic segmentations. \n",
        "\n",
        "U-Net consists of a contracting path and an expansive path. \n",
        "\n",
        "* The contracting path follows a typical convolutional nerual \n",
        "neural network architecture, in which we first apply a 3x3 valid convoltions to the input image with 3 input channels(RGB) and get 64 output channels. Then we apply ReLU to this output. Next we down-sample with a 2x2 max pooling operations with stride = 2, which doubles the number of feature channels. Repeat this process 5 times. At each iteration, the number of input channels is the number of output channels of the previous convolutional layer. At the end of the fifth iteration, however, we performed an up sampling insteatd of a down-sampling, which starts the expansive path of the architecture.\n",
        "\n",
        "* At the beginning of the expansive path, we perform a 2x2 up-convolution that halves the number of feature channels, then concatenate it with the corresponding output from the contractiing path (see figure above). Next we again apply a 3x3 valid convolution followed by ReLU to the output from the previous step. Repeat this process five times. At each iteration, the number of input channels is the number of output channels of the previous convolutional layer. At the end of the fifth iteration, instead of another up-sampling, we apply a 1x1 convolution and get a output segmentation map with 2 channels, with which each channel represents one label(blood vessel and non-blood vessel in our case).\n",
        "\n",
        "In the concatenation step, cropping of the output from contracting path is needed since we used valid convolutions, from which we lost the border pixels. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJoWqNcLxYbq"
      },
      "outputs": [],
      "source": [
        "class doubleConv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(doubleConv,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride = 1, padding = 'same') \n",
        "    self.relu = nn.ReLU()\n",
        "    self.norm = nn.BatchNorm2d(out_channels)\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride = 1, padding = 'same')\n",
        "\n",
        "  def forward(self,x):\n",
        "    return nn.Sequential(self.conv1,self.norm, self.relu, self.conv2, self.norm, self.relu)(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk1U5VmS3Ph0"
      },
      "outputs": [],
      "source": [
        "class UNET(nn.Module):\n",
        "  def __init__(self, in_channels = 3, out_channels = 1, channel_list = [64,128]):\n",
        "    super(UNET,self).__init__()\n",
        "    self.contract = nn.ModuleList()\n",
        "    self.expand = nn.ModuleList()\n",
        "    self.expand_UpSamp = nn.ModuleList()\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "\n",
        "    # Contraction path \n",
        "    for num in channel_list:\n",
        "      self.contract.append(doubleConv(in_channels, num))\n",
        "      in_channels = num\n",
        "\n",
        "    # The end of contraction path\n",
        "    self.end_contract = doubleConv(channel_list[-1], channel_list[-1]*2)\n",
        "\n",
        "    # In expansion path, we concatenate the inputs with outputs from contraction path, so number of input channels are doubled.\n",
        "    for num in channel_list[::-1]:\n",
        "      # up conv\n",
        "      self.expand_UpSamp.append(nn.ConvTranspose2d(num*2, num, 2, 2))\n",
        "\n",
        "      # Double convolution \n",
        "      self.expand.append(doubleConv(num*2, num))\n",
        "\n",
        "    # The last step of expansion path, which yields the final output\n",
        "    self.final = nn.Conv2d(channel_list[0],out_channels, kernel_size = 1)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # store the outputs from contraction path for later concatenations\n",
        "    concat_list = []\n",
        "\n",
        "    # Perform the contraction path of UNET\n",
        "    for contract in self.contract:\n",
        "      x = contract(x)\n",
        "      concat_list.append(x)\n",
        "      x = self.pool(x)\n",
        "\n",
        "    x = self.end_contract(x)\n",
        "\n",
        "\n",
        "    # start concatenation from the end of the list concat_list. Reverse the concat_list for convenience\n",
        "\n",
        "    concat_list = concat_list[::-1]\n",
        "    for i in range(len(self.expand)):\n",
        "      x = self.expand_UpSamp[i](x)\n",
        "\n",
        "      # match the skip connection with the size of x before concatenating.\n",
        "      # pad the image with smaller size, x, with 0's so that it has the same number of pixels as concat_list[i]\n",
        "      \n",
        "      if concat_list[i].shape != x.shape:\n",
        "        x = transforms.functional.resize(x, size = concat_list[i].shape[2:])\n",
        "\n",
        "      # concatenate the skip connection with x, along the channels\n",
        "      concat = torch.cat((concat_list[i],x), dim = 1)\n",
        "\n",
        "      # Double convolution on the concatenated inputs \n",
        "      x = self.expand[i](concat)\n",
        "\n",
        "    x = self.final(x)\n",
        "\n",
        "    return torch.sigmoid(x)\n",
        "\n",
        "      \n",
        "  \n",
        "\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RK57_pZhDlF"
      },
      "source": [
        "We define the loss function to be the cross entropy loss and an optimizer to be stochastic gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U87gcIFqg6wy"
      },
      "outputs": [],
      "source": [
        "unet = UNET()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4arIatNGQrO"
      },
      "outputs": [],
      "source": [
        "unet.to(device)\n",
        "optimizer = optim.SGD(unet.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rd_-74Ih8Ip"
      },
      "outputs": [],
      "source": [
        "from re import I\n",
        "loss_list = []\n",
        "for epoch in range(20):  # loop over the dataset twice\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        pred = unet(inputs)\n",
        "        loss_list = []\n",
        "        loss = nn.BCELoss()(pred, labels)\n",
        "        #loss = nn.KLDivLoss()(pred, labels)\n",
        "        #loss = nn.BCEwithLogitLoss()(pred, labels)\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    loss_list.append(running_loss/(i+1))\n",
        "        # print statistics\n",
        "    print('Avg. loss this epoch: ', loss.item())\n",
        "\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls = list(range(1,1+len(loss_list)))\n",
        "\n",
        "plt.plt(ls,loss_list)\n",
        "plt.title(\"Training Binary Cross Entropy Loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"epoch\")\n",
        "plt.xticks(ls)\n",
        "plt.show"
      ],
      "metadata": {
        "id": "rRx3vxJRABJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train on a smaller dataset"
      ],
      "metadata": {
        "id": "FT8ikVq8JNTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smallset, _ = torch.utils.data.random_split(trainset, [5, 5])\n",
        "smallloader = torch.utils.data.DataLoader(smallset, batch_size=3, shuffle=True, num_workers=0)"
      ],
      "metadata": {
        "id": "otz5owlGJVcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcAArytE2u86"
      },
      "source": [
        "To check if our model is overfitted or underfitted, we use the validation set and compute the validation error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSyX0jrH2olc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ecd05d-851e-4dda-96a7-9b3debc3727e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation error: 0.2518784314393997\n"
          ]
        }
      ],
      "source": [
        "# validation error\n",
        "acc_loss = 0\n",
        "for i, data in enumerate(valloader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    pred = unet(inputs)\n",
        "    #loss = nn.CrossEntropyLoss(reduce = 'none')(pred, labels)\n",
        "    loss = nn.BCELoss()(pred, labels)\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "    # print statistics\n",
        "    acc_loss += loss.item()\n",
        "\n",
        "print(\"Validation error:\", acc_loss/(i+1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RCmcU48srFW"
      },
      "source": [
        "Our model seems underfitted since the training error is still high after two rounds of training. The dataset we have is too small in this case We do data augmentation to resolve this problem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6L4N0a8tCKE"
      },
      "outputs": [],
      "source": [
        "class retinaDataset2(torch.utils.data.Dataset):\n",
        "  def __init__(self, length=15):\n",
        "      'Initialization'\n",
        "      self.X = []\n",
        "      self.y = []\n",
        "      self.length = length\n",
        "  \n",
        "  def __len__(self):\n",
        "      'Denotes the total number of samples'\n",
        "      return self.length\n",
        "\n",
        "  def transform(self, image):\n",
        "      X = transforms.RandomChoice([transforms.RandomRotation([-90,90]), transforms.RandomHorizontalFlip(),transforms.RandomAutocontrast(),transforms.RandomVerticalFlip()])(image)\n",
        "      X = transforms.ToTensor()(X)\n",
        "\n",
        "      return X\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      'Generates one sample of data'\n",
        "      # Select sample\n",
        "      image = Image.open(f'{index + 1}_training.tif')\n",
        "      label = Image.open(f'{index + 1}_manual1.gif')\n",
        "      X = self.transform(image)\n",
        "      #X1 = self.transform_aug1(image)\n",
        "      y = self.transform(label)\n",
        "      #y1 = self.transform_aug1(label)\n",
        "      return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KB1EMEcrxE_j"
      },
      "outputs": [],
      "source": [
        "loss_list_aug = []\n",
        "full_aug_set = retinaDataset2()\n",
        "aug_train, aug_val = torch.utils.data.random_split(full_aug_set, [10, 5])\n",
        "for epoch in range(20):  # loop over the dataset multiple times\n",
        "    trainloader_aug = torch.utils.data.DataLoader(aug_train, batch_size=3, shuffle=True, num_workers=0)\n",
        "    valloader_aug = torch.utils.data.DataLoader(aug_val, batch_size=1, shuffle=True, num_workers=0)\n",
        "    acc_loss = 0\n",
        "    for i, data in enumerate(trainloader_aug, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        pred = unet(inputs)\n",
        "        loss = nn.BCELoss()(pred, labels)\n",
        "        acc_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_list_aug.append(acc_loss/(i+1))\n",
        "    # print statistics\n",
        "    print('Avg. loss this epoch: ', acc_loss/(i+1))\n",
        "\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFvbu7G9rJYb"
      },
      "outputs": [],
      "source": [
        "#with torch.no_grad():\n",
        "for i, data in enumerate(trainloader, 0):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = unet(images)\n",
        "    imshow_gpu(torchvision.utils.make_grid(outputs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KZy3lVpCR8T",
        "outputId": "93f27aa9-fb91-4656-c70b-03751a952d8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation error: 0.3114476203918457\n"
          ]
        }
      ],
      "source": [
        "# validation error\n",
        "acc_loss = 0\n",
        "for i, data in enumerate(valloader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    pred = unet(inputs)\n",
        "    #loss = nn.CrossEntropyLoss(reduce = 'none')(pred, labels)\n",
        "    loss = nn.BCELoss()(pred, labels)\n",
        "    loss_list.append(loss.item())\n",
        "\n",
        "    # print statistics\n",
        "    acc_loss += loss.item()\n",
        "\n",
        "print(\"Validation error:\", acc_loss/(i+1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2cN_zR3y2hX"
      },
      "outputs": [],
      "source": [
        "def imshow2(img):\n",
        "    #img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.detach().numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHbFXBHQ9wwq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRKSs3RhXrnZ"
      },
      "outputs": [],
      "source": [
        "class testDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, length = 5):\n",
        "      'Initialization'\n",
        "      self.length = length\n",
        "  \n",
        "  def __len__(self):\n",
        "      'Denotes the total number of samples'\n",
        "      return self.length\n",
        "\n",
        "  def transform(self, image):\n",
        "    X = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])(image)\n",
        "    return X\n",
        "\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "      'Generates one sample of data'\n",
        "      # Select sample\n",
        "      image = Image.open(f'{index + 1}_test.tif')\n",
        "      X = self.transform(image)\n",
        "      return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_EXXwK4YOgz"
      },
      "outputs": [],
      "source": [
        "testSet = testDataset()\n",
        "testloader = torch.utils.data.DataLoader(testSet, batch_size=1, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRiy7zyz9nVr",
        "outputId": "09196194-0142-4305-d51c-5165ceb77e9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dice coefficient:  0.12690446316544182\n",
            "Dice coefficient:  0.11412106262688\n",
            "Dice coefficient:  0.14114550240537352\n",
            "Dice coefficient:  0.5625997769370393\n",
            "Dice coefficient:  0.09195789068884296\n",
            "4\n",
            "Average dice coefficient: 0.2073457391647155\n"
          ]
        }
      ],
      "source": [
        "def single_dice_coef(label, pred):\n",
        "    label = label.detach().cpu().numpy()\n",
        "    pred = np.array((pred > 0.5).float())\n",
        "    intersection = np.sum(label * pred)\n",
        "    if (np.sum(label)==0) and (np.sum(pred)==0):\n",
        "        return 1\n",
        "    return (2*intersection) / (np.sum(label) + np.sum(pred))\n",
        "\n",
        "\n",
        "acc_dice = 0\n",
        "for i, data in enumerate(valloader_aug,0):\n",
        "  images, labels = data\n",
        "  pred = unet(images.to(device))\n",
        "  dice = single_dice_coef(labels, pred.cpu())\n",
        "  acc_dice += dice\n",
        "  print(\"Dice coefficient: \", dice)\n",
        "\n",
        "print(\"Average dice coefficient:\",acc_dice/(i+1) )\n",
        "  \n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gabLCo9YdJbR"
      },
      "outputs": [],
      "source": [
        "for i, data in enumerate(testloader, 0):\n",
        "    images= data\n",
        "    images= images.to(device)\n",
        "\n",
        "    outputs = unet(images)\n",
        "    outputs = (outputs > 0.3).float()\n",
        "    plt.title(f\"Predition of test image {i+1}\")\n",
        "    imshow_gpu(torchvision.utils.make_grid(outputs))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of EML Assignment 3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}